{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 多位数字识别\n",
    "\n",
    "应用背景：将建筑物添加到谷歌地图中，街景车拍摄建筑物，同时记录各张照片中建筑物相关的GPS坐标，通过机器识别每张图片上的门牌号码，方便谷歌地图数据库在正确的位置添加该建筑地址。\n",
    "\n",
    "多位数字识别问题是一种特殊类型的序列识别（sequence recognition），其特殊之处在于：序列的长度是有界的，极少出现门牌号包括5位以上的数字。本例中假设门牌号最长5位。\n",
    "\n",
    "传统做法：将操作步骤分为定位(localization)、分割(segmentation)、识别(recognition)三个阶段，[Goodfellow,2014](https://arxiv.org/abs/1312.6082)提出一种基于深度卷积神经网络的三个阶段整合的方案，这一方案也是本例实践的主要指导。本例代码主要参考[potterhsu](https://github.com/potterhsu/SVHNClassifier)、[thomalm](https://github.com/thomalm/svhn-multi-digit)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理方面，由于SVHN数据集某些数字裁剪的太紧，导致地址数字被裁剪操作剪除。因此需要将裁剪区域范围扩大：\n",
    "> expand this bounding box by 30% in both the x and the y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcess(image, bbox_left, bbox_top, bbox_width, bbox_height):\n",
    "        cropped_left, cropped_top, cropped_width, cropped_height = (int(round(bbox_left - 0.15 * bbox_width)),\n",
    "                                                                    int(round(bbox_top - 0.15 * bbox_height)),\n",
    "                                                                    int(round(bbox_width * 1.3)),\n",
    "                                                                    int(round(bbox_height * 1.3)))\n",
    "        image = image.crop([cropped_left, cropped_top, cropped_left + cropped_width, cropped_top + cropped_height])\n",
    "        image = image.resize([64, 64])\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为增加数据样本量，将原本一张64$*$64像素的图片随机裁剪为若干54$*$54像素的图片：\n",
    "> crop a 54$*$54 pixel image from a random location within the 64$*$64 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Donkey(object):\n",
    "    @staticmethod\n",
    "    def _preprocess(image):\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "        image = tf.multiply(tf.subtract(image, 0.5), 2)\n",
    "        image = tf.image.resize(image, [64, 64])\n",
    "        image = tf.image.random_crop(image, [54, 54, 3])\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_function(proto):\n",
    "        features = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'length': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'digits': tf.io.FixedLenFeature([5], tf.int64)\n",
    "        }\n",
    "        parsed_features = tf.io.parse_single_example(proto, features)\n",
    "        image = Donkey._preprocess(tf.io.decode_raw(parsed_features['image'], tf.uint8))\n",
    "        length = tf.cast(parsed_features['length'], tf.int32)\n",
    "        digits = tf.cast(parsed_features['digits'], tf.int32)\n",
    "        return image, length, digits\n",
    "\n",
    "    @staticmethod\n",
    "    def build_batch(path_to_tfrecords_file, num_examples, batch_size, shuffled):\n",
    "        assert tf.io.gfile.exists(path_to_tfrecords_file), '%s not found' % path_to_tfrecords_file\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(filenames=[path_to_tfrecords_file])\n",
    "        dataset = dataset.map(Donkey._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        if shuffled:\n",
    "            dataset = dataset.shuffle(buffer_size=int(0.4 * num_examples))\n",
    "\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型结构及具体参数沿用Goodfellow的模型方案：\n",
    "> - Our best architecture consists of eight convolutional hidden layers, one locally connected hidden layer, and two densely connected hidden layers. All connections are feedforward and go from one layer to the next (no skip connections).\n",
    "> - The number of units at each spatial location in each layer is [48, 64, 128, 160] for the first four layers and 192 for all other locally connected layers. The fully connected layers contain 3,072 units each. \n",
    "> - Each convolutional layer includes max pooling and subtractive normalization. The max pooling window size is 2$*$2. \n",
    "> - All convolutions use zero padding on the input to preserve representation size.\n",
    "> - All convolution kernels were of size 5$*$5. We trained with dropout applied to all hidden layers but not the input.\n",
    "\n",
    "模型机构如图所示：\n",
    "![model-graph](../img/model-graph.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, drop_rate):\n",
    "        super().__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        return self.inference(x, self.drop_rate, training=training)\n",
    "\n",
    "    @staticmethod\n",
    "    def inference(self, x, drop_rate, training):\n",
    "        hidden1 = tf.keras.layers.Conv2D(filters=48, kernel_size=(5, 5), padding='same')(x)\n",
    "        hidden1 = tf.keras.layers.BatchNormalization()(hidden1, training=training)\n",
    "        hidden1 = tf.keras.layers.ReLU()(hidden1)\n",
    "        hidden1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(hidden1)\n",
    "        hidden1 = tf.keras.layers.Dropout(rate=drop_rate)(hidden1, training=training)\n",
    "\n",
    "        hidden2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same')(hidden1)\n",
    "        hidden2 = tf.keras.layers.BatchNormalization()(hidden2, training=training)\n",
    "        hidden2 = tf.keras.layers.ReLU()(hidden2)\n",
    "        hidden2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(hidden2)\n",
    "        hidden2 = tf.keras.layers.Dropout(rate=drop_rate)(hidden2, training=training)\n",
    "\n",
    "        hidden3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(5, 5), padding='same')(hidden2)\n",
    "        hidden3 = tf.keras.layers.BatchNormalization()(hidden3, training=training)\n",
    "        hidden3 = tf.keras.layers.ReLU()(hidden3)\n",
    "        hidden3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(hidden3)\n",
    "        hidden3 = tf.keras.layers.Dropout(rate=drop_rate)(hidden3, training=training)\n",
    "\n",
    "        hidden4 = tf.keras.layers.Conv2D(filters=160, kernel_size=(5, 5), padding='same')(hidden3)\n",
    "        hidden4 = tf.keras.layers.BatchNormalization()(hidden4, training=training)\n",
    "        hidden4 = tf.keras.layers.ReLU()(hidden4)\n",
    "        hidden4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(hidden4)\n",
    "        hidden4 = tf.keras.layers.Dropout(rate=drop_rate)(hidden4, training=training)\n",
    "\n",
    "        hidden5 = tf.keras.layers.Conv2D(filters=192, kernel_size=(5, 5), padding='same')(hidden4)\n",
    "        hidden5 = tf.keras.layers.BatchNormalization()(hidden5, training=training)\n",
    "        hidden5 = tf.keras.layers.ReLU()(hidden5)\n",
    "        hidden5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(hidden5)\n",
    "        hidden5 = tf.keras.layers.Dropout(rate=drop_rate)(hidden5, training=training)\n",
    "\n",
    "        hidden6 = tf.keras.layers.Conv2D(filters=192, kernel_size=(5, 5), padding='same')(hidden5)\n",
    "        hidden6 = tf.keras.layers.BatchNormalization()(hidden6, training=training)\n",
    "        hidden6 = tf.keras.layers.ReLU()(hidden6)\n",
    "        hidden6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(hidden6)\n",
    "        hidden6 = tf.keras.layers.Dropout(rate=drop_rate)(hidden6, training=training)\n",
    "\n",
    "        hidden7 = tf.keras.layers.Conv2D(filters=192, kernel_size=(5, 5), padding='same')(hidden6)\n",
    "        hidden7 = tf.keras.layers.BatchNormalization()(hidden7, training=training)\n",
    "        hidden7 = tf.keras.layers.ReLU()(hidden7)\n",
    "        hidden7 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(hidden7)\n",
    "        hidden7 = tf.keras.layers.Dropout(rate=drop_rate)(hidden7, training=training)\n",
    "\n",
    "        hidden8 = tf.keras.layers.Conv2D(filters=192, kernel_size=(5, 5), padding='same')(hidden7)\n",
    "        hidden8 = tf.keras.layers.BatchNormalization()(hidden8, training=training)\n",
    "        hidden8 = tf.keras.layers.ReLU()(hidden8)\n",
    "        hidden8 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(hidden8)\n",
    "        hidden8 = tf.keras.layers.Dropout(rate=drop_rate)(hidden8, training=training)\n",
    "\n",
    "        flatten = tf.keras.layers.Flatten()(hidden8)\n",
    "\n",
    "        hidden9 = tf.keras.layers.Dense(units=3072, activation='relu')(flatten)\n",
    "        hidden10 = tf.keras.layers.Dense(units=3072, activation='relu')(hidden9)\n",
    "\n",
    "        length = tf.keras.layers.Dense(units=7)(hidden10)\n",
    "        digit1 = tf.keras.layers.Dense(units=11)(hidden10)\n",
    "        digit2 = tf.keras.layers.Dense(units=11)(hidden10)\n",
    "        digit3 = tf.keras.layers.Dense(units=11)(hidden10)\n",
    "        digit4 = tf.keras.layers.Dense(units=11)(hidden10)\n",
    "        digit5 = tf.keras.layers.Dense(units=11)(hidden10)\n",
    "\n",
    "        length_logits, digits_logits = length, tf.stack([digit1, digit2, digit3, digit4, digit5], axis=1)\n",
    "        return length_logits, digits_logits\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(length_logits, digits_logits, length_labels, digits_labels):\n",
    "        length_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(length_labels, length_logits))\n",
    "        digit1_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(digits_labels[:, 0], digits_logits[:, 0, :]))\n",
    "        digit2_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(digits_labels[:, 1], digits_logits[:, 1, :]))\n",
    "        digit3_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(digits_labels[:, 2], digits_logits[:, 2, :]))\n",
    "        digit4_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(digits_labels[:, 3], digits_logits[:, 3, :]))\n",
    "        digit5_cross_entropy = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(digits_labels[:, 4], digits_logits[:, 4, :]))\n",
    "\n",
    "        loss = (length_cross_entropy + digit1_cross_entropy +\n",
    "                digit2_cross_entropy + digit3_cross_entropy +\n",
    "                digit4_cross_entropy + digit5_cross_entropy)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取数据集中的样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Meta(object):\n",
    "    def __init__(self):\n",
    "        self.num_train_examples = None\n",
    "        self.num_val_examples = None\n",
    "        self.num_test_examples = None\n",
    "\n",
    "    def save(self, path_to_json_file):\n",
    "        with open(path_to_json_file, 'w') as f:\n",
    "            content = {\n",
    "                'num_examples': {\n",
    "                    'train': self.num_train_examples,\n",
    "                    'val': self.num_val_examples,\n",
    "                    'test': self.num_test_examples\n",
    "                }\n",
    "            }\n",
    "            json.dump(content, f)\n",
    "\n",
    "    def load(self, path_to_json_file):\n",
    "        with open(path_to_json_file, 'r') as f:\n",
    "            content = json.load(f)\n",
    "            self.num_train_examples = content['num_examples']['train']\n",
    "            self.num_val_examples = content['num_examples']['val']\n",
    "            self.num_test_examples = content['num_examples']['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算模型的accuracy等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, path_to_eval_log_dir):\n",
    "        self.summary_writer = tf.summary.create_file_writer(path_to_eval_log_dir)\n",
    "\n",
    "    @tf.function\n",
    "    def evaluate(self, path_to_checkpoint, path_to_tfrecords_file, num_examples, global_step):\n",
    "        batch_size = 128\n",
    "        num_batches = num_examples // batch_size\n",
    "        needs_include_length = False\n",
    "\n",
    "        model = Model(0.0)\n",
    "\n",
    "        image_batch, length_batch, digits_batch = Donkey.build_batch(path_to_tfrecords_file,\n",
    "                                                                     num_examples=num_examples,\n",
    "                                                                     batch_size=batch_size,\n",
    "                                                                     shuffled=False)\n",
    "        length_logits, digits_logits = model(image_batch, training=True)\n",
    "        length_predictions = tf.argmax(length_logits, axis=1)\n",
    "        digits_predictions = tf.argmax(digits_logits, axis=2)\n",
    "\n",
    "        if needs_include_length:\n",
    "            labels = tf.concat([tf.reshape(length_batch, [-1, 1]), digits_batch], axis=1)\n",
    "            predictions = tf.concat([tf.reshape(length_predictions, [-1, 1]), digits_predictions], axis=1)\n",
    "        else:\n",
    "            labels = digits_batch\n",
    "            predictions = digits_predictions\n",
    "\n",
    "        labels_string = tf.reduce_join(tf.as_string(labels), axis=1)\n",
    "        predictions_string = tf.reduce_join(tf.as_string(predictions), axis=1)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(labels_string, predictions_string), tf.float32))\n",
    "        accuracy_val = accuracy.numpy().item()\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.image('image', image_batch, step=global_step)\n",
    "            tf.summary.scalar('accuracy', accuracy_val, step=global_step)\n",
    "            tf.summary.histogram('variables',\n",
    "                                 tf.concat([tf.reshape(var, [-1]) for var in tf.trainable_variables()], axis=0),\n",
    "                                 step=global_step)\n",
    "\n",
    "        return accuracy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train(path_to_train_tfrecords_file, num_train_examples, path_to_val_tfrecords_file, num_val_examples,\n",
    "           path_to_train_log_dir, path_to_restore_checkpoint_file, training_options):\n",
    "    batch_size = training_options['batch_size']\n",
    "    initial_patience = training_options['patience']\n",
    "    num_steps_to_show_loss = 100\n",
    "    num_steps_to_check = 1000\n",
    "\n",
    "    train_dataset = Donkey.build_batch(path_to_train_tfrecords_file, num_examples=num_train_examples,\n",
    "                                        batch_size=batch_size, shuffled=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model = Model(0.2)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=training_options['learning_rate'])\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    summary_writer = tf.summary.create_file_writer(path_to_train_log_dir)\n",
    "    evaluator = Evaluator(os.path.join(path_to_train_log_dir, 'eval/val'))\n",
    "\n",
    "    # tf.keras.Model内置检查点\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "    if path_to_restore_checkpoint_file:\n",
    "        checkpoint.restore(path_to_restore_checkpoint_file).expect_partial()\n",
    "        print('Model restored from file: %s' % path_to_restore_checkpoint_file)\n",
    "\n",
    "    print('Start training')\n",
    "    patience = initial_patience\n",
    "    best_accuracy = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    while True:\n",
    "        for image_batch, length_batch, digits_batch in train_dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                length_logits, digits_logits = model(image_batch, training=True)\n",
    "                loss = Model.loss(length_logits, digits_logits, length_batch, digits_batch)\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if steps % num_steps_to_show_loss == 0:\n",
    "                print(f'=> {datetime.now()}: step {steps}, loss = {loss.numpy()}')\n",
    "\n",
    "            if steps % num_steps_to_check == 0:\n",
    "                print('=> Evaluating on validation dataset...')\n",
    "                path_to_latest_checkpoint_file = os.path.join(path_to_train_log_dir, 'latest.ckpt')\n",
    "                accuracy = evaluator.evaluate(path_to_latest_checkpoint_file, path_to_val_tfrecords_file,\n",
    "                                              num_val_examples, steps)\n",
    "                print('==> accuracy = %f, best accuracy %f' % (accuracy, best_accuracy))\n",
    "\n",
    "                if accuracy > best_accuracy:\n",
    "                    path_to_checkpoint_file = os.path.join(path_to_train_log_dir, 'model.ckpt')\n",
    "                    checkpoint.save(file_prefix=path_to_checkpoint_file)\n",
    "                    print('=> Model saved to file: %s' % path_to_checkpoint_file)\n",
    "                    patience = initial_patience\n",
    "                    best_accuracy = accuracy\n",
    "                else:\n",
    "                    patience -= 1\n",
    "\n",
    "                print('=> patience = %d' % patience)\n",
    "                if patience == 0:\n",
    "                    break\n",
    "\n",
    "        print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主函数，其中设置模型超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = './data'\n",
    "    path_to_train_tfrecords_file = os.path.join(data_dir, 'train.tfrecords')\n",
    "    path_to_val_tfrecords_file = os.path.join(data_dir, 'val.tfrecords')\n",
    "    path_to_tfrecords_meta_file = os.path.join(data_dir, 'meta.json')\n",
    "    path_to_train_log_dir = './logs/train'\n",
    "    path_to_restore_checkpoint_file = None\n",
    "    training_options = {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-2,\n",
    "        'patience': 100,\n",
    "        'decay_steps': 10000,\n",
    "        'decay_rate': 0.9\n",
    "    }\n",
    "    meta = Meta()\n",
    "    meta.load(path_to_tfrecords_meta_file)\n",
    "    \n",
    "    _train(path_to_train_tfrecords_file, meta.num_train_examples,\n",
    "           path_to_val_tfrecords_file, meta.num_val_examples,\n",
    "           path_to_train_log_dir, path_to_restore_checkpoint_file,\n",
    "           training_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
